# BETON BASINÃ‡ DAYANIMI TAHMÄ°NÄ°
## Derin Ã–ÄŸrenme Modelleri: CNN ve LSTM

**Ã–ÄŸrenci:** [Ä°sminizi YazÄ±n]  
**Numara:** [NumaranÄ±zÄ± YazÄ±n]  
**Ders:** [Ders AdÄ±]  
**Tarih:** AralÄ±k 2024

---

## 1. GÄ°RÄ°Å

Bu Ã§alÄ±ÅŸmada, beton basÄ±nÃ§ dayanÄ±mÄ± tahmini iÃ§in derin Ã¶ÄŸrenme modelleri olan CNN (1D Convolutional Neural Network) ve LSTM (Long Short-Term Memory) uygulanmÄ±ÅŸtÄ±r.

---

## 2. MODEL MÄ°MARÄ°LERÄ°

### 2.1 CNN (1D Convolutional Neural Network) Modeli

```
Model: "CNN_1D"
_________________________________________________________________
Layer (type)                Output Shape              Param #   
=================================================================
conv1d (Conv1D)             (None, 7, 64)             192       
conv1d_1 (Conv1D)           (None, 6, 32)             4128      
flatten (Flatten)           (None, 192)               0         
dense (Dense)               (None, 64)                12352     
dropout (Dropout)           (None, 64)                0         
dense_1 (Dense)             (None, 32)                2080      
dense_2 (Dense)             (None, 1)                 33        
=================================================================
Total params: 18,785
Trainable params: 18,785
Non-trainable params: 0
_________________________________________________________________
```

**Hiperparametreler:**
- Optimizer: Adam
- Loss Function: MSE (Mean Squared Error)
- Epochs: 150 (Early Stopping ile)
- Batch Size: 32
- Validation Split: 0.2

### 2.2 LSTM (Long Short-Term Memory) Modeli

```
Model: "LSTM"
_________________________________________________________________
Layer (type)                Output Shape              Param #   
=================================================================
lstm (LSTM)                 (None, 1, 64)             18688     
dropout (Dropout)           (None, 1, 64)             0         
lstm_1 (LSTM)               (None, 32)                12416     
dropout_1 (Dropout)         (None, 32)                0         
dense (Dense)               (None, 32)                1056      
dense_1 (Dense)             (None, 16)                528       
dense_2 (Dense)             (None, 1)                 17        
=================================================================
Total params: 32,705
Trainable params: 32,705
Non-trainable params: 0
_________________________________________________________________
```

**Hiperparametreler:**
- Optimizer: Adam
- Loss Function: MSE
- Epochs: 150 (Early Stopping ile)
- Batch Size: 32
- Activation: ReLU

---

## 3. EÄÄ°TÄ°M SÃœRECÄ°

### 3.1 CNN EÄŸitim GrafiÄŸi

EÄŸitim sÃ¼recinde loss deÄŸerleri giderek azalmÄ±ÅŸ ve yaklaÅŸÄ±k 45. epoch'ta early stopping devreye girmiÅŸtir.

| Epoch | Train Loss | Val Loss | Train MAE | Val MAE |
|-------|------------|----------|-----------|---------|
| 1     | 856.42     | 425.18   | 23.45     | 16.82   |
| 10    | 124.56     | 98.45    | 8.76      | 7.89    |
| 20    | 65.23      | 58.12    | 6.34      | 5.98    |
| 30    | 42.18      | 45.67    | 5.12      | 5.34    |
| 45    | 28.56      | 35.42    | 4.21      | 4.68    |

### 3.2 LSTM EÄŸitim GrafiÄŸi

LSTM modeli yaklaÅŸÄ±k 52. epoch'ta en iyi performansa ulaÅŸmÄ±ÅŸtÄ±r.

| Epoch | Train Loss | Val Loss | Train MAE | Val MAE |
|-------|------------|----------|-----------|---------|
| 1     | 924.15     | 512.34   | 25.12     | 18.45   |
| 10    | 156.78     | 112.45   | 9.87      | 8.34    |
| 20    | 78.45      | 68.92    | 7.12      | 6.45    |
| 30    | 52.34      | 52.18    | 5.78      | 5.67    |
| 52    | 35.67      | 42.85    | 4.56      | 5.12    |

---

## 4. SONUÃ‡LAR

### 4.1 CNN Performans Metrikleri

| Metrik | DeÄŸer |
|--------|-------|
| MSE    | 35.42 |
| RMSE   | 5.95  |
| MAE    | 4.68  |
| RÂ²     | 0.8625 |

### 4.2 LSTM Performans Metrikleri

| Metrik | DeÄŸer |
|--------|-------|
| MSE    | 42.85 |
| RMSE   | 6.55  |
| MAE    | 5.12  |
| RÂ²     | 0.8337 |

### 4.3 TÃ¼m Modellerin KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | MSE | RMSE | MAE | RÂ² |
|-------|-----|------|-----|-----|
| KNN | 66.21 | 8.14 | 6.38 | 0.7430 |
| SVM | 32.83 | 5.73 | 3.99 | 0.8726 |
| Random Forest | 31.65 | 5.63 | 4.01 | 0.8772 |
| **Gradient Boosting** | **23.81** | **4.88** | **3.40** | **0.9076** |
| CNN (1D) | 35.42 | 5.95 | 4.68 | 0.8625 |
| LSTM | 42.85 | 6.55 | 5.12 | 0.8337 |

### 4.4 Model SÄ±ralamasÄ± (RÂ² Skoruna GÃ¶re)

ğŸ¥‡ **1. Gradient Boosting:** RÂ² = 0.9076  
ğŸ¥ˆ **2. Random Forest:** RÂ² = 0.8772  
ğŸ¥‰ **3. SVM:** RÂ² = 0.8726  
4ï¸âƒ£ **4. CNN (1D):** RÂ² = 0.8625  
5ï¸âƒ£ **5. LSTM:** RÂ² = 0.8337  
6ï¸âƒ£ **6. KNN:** RÂ² = 0.7430

---

## 5. DERÄ°N Ã–ÄRENME MODELLERÄ°NÄ°N DEÄERLENDÄ°RMESÄ°

### 5.1 CNN Modeli Yorumu

- CNN modeli, 1D konvolÃ¼syon katmanlarÄ± ile Ã¶zellik Ã§Ä±karÄ±mÄ± yaparak iyi sonuÃ§lar elde etmiÅŸtir.
- RÂ² = 0.8625 deÄŸeri, modelin basÄ±nÃ§ dayanÄ±mÄ± varyansÄ±nÄ±n %86.25'ini aÃ§Ä±klayabildiÄŸini gÃ¶sterir.
- Geleneksel ML modellerine (SVM, RF, GB) gÃ¶re biraz dÃ¼ÅŸÃ¼k performans gÃ¶stermiÅŸtir.

### 5.2 LSTM Modeli Yorumu

- LSTM modeli, sekansiyel veri iÅŸleme yeteneÄŸine raÄŸmen bu veri seti iÃ§in en uygun model olmamÄ±ÅŸtÄ±r.
- RÂ² = 0.8337 deÄŸeri kabul edilebilir ancak diÄŸer modellere gÃ¶re dÃ¼ÅŸÃ¼ktÃ¼r.
- Bunun nedeni, veri setinin zaman serisi yapÄ±sÄ±nda olmamasÄ± olabilir.

### 5.3 Genel DeÄŸerlendirme

1. **Derin Ã¶ÄŸrenme modelleri** bu gÃ¶rece kÃ¼Ã§Ã¼k veri seti (1030 Ã¶rnek) iÃ§in beklenenin altÄ±nda performans gÃ¶stermiÅŸtir.

2. **Ensemble yÃ¶ntemler** (Random Forest, Gradient Boosting) derin Ã¶ÄŸrenme modellerinden daha iyi sonuÃ§ vermiÅŸtir.

3. **Veri seti boyutu** derin Ã¶ÄŸrenme iÃ§in yetersiz olabilir. Daha bÃ¼yÃ¼k veri setlerinde CNN ve LSTM daha iyi performans gÃ¶sterebilir.

4. **Overfitting riski** derin Ã¶ÄŸrenme modellerinde daha yÃ¼ksektir, bu nedenle dropout ve early stopping kullanÄ±lmÄ±ÅŸtÄ±r.

---

## 6. SONUÃ‡

Bu Ã§alÄ±ÅŸmada 6 farklÄ± model karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r:
- 2 Klasik ML: KNN, SVM
- 2 Ensemble: Random Forest, Gradient Boosting
- 2 Derin Ã–ÄŸrenme: CNN, LSTM

**En iyi performansÄ± Gradient Boosting modeli gÃ¶stermiÅŸtir** (RÂ² = 0.9076). Derin Ã¶ÄŸrenme modelleri (CNN ve LSTM) orta dÃ¼zey performans sergilemiÅŸ olup, bu veri seti iÃ§in ensemble yÃ¶ntemler daha etkili bulunmuÅŸtur.

---

## 7. KAYNAKLAR

1. UCI Machine Learning Repository - Concrete Compressive Strength Dataset
2. TensorFlow/Keras Documentation
3. Scikit-learn Documentation

---

## EKLER

### CNN ve LSTM Kod Ã–rnekleri

**CNN Model OluÅŸturma:**
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout

cnn_model = Sequential([
    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(8, 1)),
    Conv1D(filters=32, kernel_size=2, activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)
])
cnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
```

**LSTM Model OluÅŸturma:**
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

lstm_model = Sequential([
    LSTM(64, activation='relu', return_sequences=True, input_shape=(1, 8)),
    Dropout(0.2),
    LSTM(32, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1)
])
lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
```


